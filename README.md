# 🚗 ML Security in Autonomous Vehicles

A university group project for COMP1806 (Information Security) that investigates cybersecurity vulnerabilities in autonomous vehicles powered by Machine Learning.

## 📘 Project Overview

This project examines how AVs (Autonomous Vehicles) use ML to make real-time decisions, and how attackers can exploit these systems. We explore:
- Attack vectors (model poisoning, adversarial examples, sensor spoofing, backdoor attacks, and more)
- Defense mechanisms (adversarial training, sensor fusion, anomaly detection, etc.)
- Real-world implications and countermeasures

## 🧠 Team Contributions

- **Bryan Hernandez Upegui** – Introduction, Use Case, Attack Team  
- **Ben Peverall** – Attack Team  
- **Mahammad Isgandarzada** – Defense Team  
- **Neebithan Baskaramoorthy** – Defense Team, Attack Graph  
- **Luis Alexander Yunga Mendoza** – Attack Team  

## 🛡️ Key Concepts Covered

- Adversarial Attacks (visual noise, sensor confusion)
- Model Poisoning (malicious data injection)
- Sensor Spoofing (GPS/Radar/Utrasonic spoofing)
- Multi-sensor data validation
- Backdoor vulnerabilities
- Attack graph modeling

## 🗂️ Files Included

- 📄 `COMP1806_Autonomous_Vehicles_Security_Report.pdf` – Full coursework report  
- 🧾 `README.md` – This file  

---

## Tools & Technologies

- Machine Learning (ML)
- Autonomous Driving Systems
- Information Security principles
- Cyber Attack Modeling

## 💬 Acknowledgements

This project was submitted as part of the coursework for the COMP1806 module at the University of Greenwich.

