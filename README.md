# ğŸš— ML Security in Autonomous Vehicles

A university group project for COMP1806 (Information Security) that investigates cybersecurity vulnerabilities in autonomous vehicles powered by Machine Learning.

## ğŸ“˜ Project Overview

This project examines how AVs (Autonomous Vehicles) use ML to make real-time decisions, and how attackers can exploit these systems. We explore:
- Attack vectors (model poisoning, adversarial examples, sensor spoofing, backdoor attacks, and more)
- Defense mechanisms (adversarial training, sensor fusion, anomaly detection, etc.)
- Real-world implications and countermeasures

## ğŸ§  Team Contributions

- **Bryan Hernandez Upegui** â€“ Introduction, Use Case, Attack Team  
- **Ben Peverall** â€“ Attack Team  
- **Mahammad Isgandarzada** â€“ Defense Team  
- **Neebithan Baskaramoorthy** â€“ Defense Team, Attack Graph  
- **Luis Alexander Yunga Mendoza** â€“ Attack Team  

## ğŸ›¡ï¸ Key Concepts Covered

- Adversarial Attacks (visual noise, sensor confusion)
- Model Poisoning (malicious data injection)
- Sensor Spoofing (GPS/Radar/Utrasonic spoofing)
- Multi-sensor data validation
- Backdoor vulnerabilities
- Attack graph modeling

## ğŸ—‚ï¸ Files Included

- ğŸ“„ `COMP1806_Autonomous_Vehicles_Security_Report.pdf` â€“ Full coursework report  
- ğŸ§¾ `README.md` â€“ This file  

---

## Tools & Technologies

- Machine Learning (ML)
- Autonomous Driving Systems
- Information Security principles
- Cyber Attack Modeling

## ğŸ’¬ Acknowledgements

This project was submitted as part of the coursework for the COMP1806 module at the University of Greenwich.

